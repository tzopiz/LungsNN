{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Сегментация радионуклидных изображений легких"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2ae7c9587ca147a6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install accelerate\n",
    "import numpy as np\n",
    "import albumentations\n",
    "import random\n",
    "import torch\n",
    "import os\n",
    "\n",
    "from pycocotools.coco import COCO\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from accelerate import Accelerator\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.nn import functional as F\n",
    "from matplotlib import pyplot as plt\n",
    "from os.path import join as pjoin\n",
    "from main import create_masks_for_all_images\n",
    "from dataset import LunksDataset\n",
    "from Unet import UNet, count_model_params\n",
    "from MeanIoU import MeanIoU\n",
    "from DiceLoss import DiceLoss\n",
    "from train import (\n",
    "    CheckpointSaver,\n",
    "    load_checkpoint,\n",
    "    train\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Установка начального значения генераторов случайных чисел"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "127eaa8699c03958"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def seed_everything(seed: int = 314159, torch_deterministic: bool = False) -> None:\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.use_deterministic_algorithms(torch_deterministic)\n",
    "\n",
    "\n",
    "seed_everything(42, torch_deterministic=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "872d6b58da478b94",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "annFile = 'instances_default.json'\n",
    "coco = COCO(annFile)\n",
    "\n",
    "create_masks_for_all_images(coco, \"Dataset/Masks\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3393261bec1b1d6d",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Преобразования изображений (аугментации)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f0f5bb47ae33b71f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 256\n",
    "transforms = albumentations.Compose(\n",
    "    [\n",
    "        albumentations.Resize(height=IMAGE_SIZE, width=IMAGE_SIZE, p=1.0),\n",
    "        albumentations.HorizontalFlip(p=0.5),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5a95d347c8c6b17c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "full_dataset = LunksDataset(root_dir=\"Dataset\", transforms = transforms)\n",
    "train_size = int(0.7 * len(full_dataset))\n",
    "val_size = int(0.2 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(full_dataset, [train_size, val_size, test_size])\n",
    "\n",
    "print('Количество изображений в полном датасете:',len(full_dataset))\n",
    "print('Количество изображений в тренировочном датасете:',len(train_dataset))\n",
    "print('Количество изображений в валидационном датасете:',len(val_dataset))\n",
    "print('Количество изображений в тестовом датасете:',len(test_dataset))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1fb600c0447d7b99",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Настройка гиперпараметров"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a810c2672b592447"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-4\n",
    "BATCH_SIZE = 4\n",
    "NUM_WORKERS = 2\n",
    "EPOCH_NUM = 20\n",
    "CHECKPOINTS_DIR = \"checkpoints\"\n",
    "TENSORBOARD_DIR = \"tensorboard\"\n",
    "RM_CHECKPOINTS_DIR = False\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b5a9bfce52e8262a",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Создание модели"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "590c14694ae74d86"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, shuffle=True\n",
    ")\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, shuffle=True\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, shuffle=True\n",
    ")\n",
    "\n",
    "model = UNet(in_channels=3, out_channels=1)\n",
    "\n",
    "loss_fn = DiceLoss()\n",
    "metric_fn = MeanIoU()\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "    optimizer=optimizer, step_size=5, gamma=0.8\n",
    ") # уменьшение скорости обучения"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "acbcf020ae117519",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Подготовка модели, данных и оптимизатора к обучению"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7359876d3d373722"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "accelerator = Accelerator(cpu=False, mixed_precision=\"fp16\")\n",
    "os.makedirs(CHECKPOINTS_DIR, exist_ok=True)\n",
    "checkpointer = CheckpointSaver(\n",
    "    accelerator=accelerator,\n",
    "    model=model,\n",
    "    metric_name=\"DICE\",\n",
    "    save_dir=CHECKPOINTS_DIR,\n",
    "    rm_save_dir=RM_CHECKPOINTS_DIR,\n",
    "    max_history=5,\n",
    "    should_minimize=False,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1b3a376e932f5ab0"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "os.makedirs(TENSORBOARD_DIR, exist_ok=True)\n",
    "tensorboard_logger = torch.utils.tensorboard.SummaryWriter(log_dir=TENSORBOARD_DIR)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "17050396c8c04b3c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model, optimizer, train_dataloader, val_dataloader, lr_scheduler = accelerator.prepare(\n",
    "    model, optimizer, train_dataloader, val_dataloader, lr_scheduler\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f9849f78977eac63",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Обучение модели"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bc0b6cf3e962bacb"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    loss_function=loss_fn,\n",
    "    metric_function=metric_fn,\n",
    "    lr_scheduler=lr_scheduler,\n",
    "    accelerator=accelerator,\n",
    "    epoch_num=EPOCH_NUM,\n",
    "    checkpointer=checkpointer,\n",
    "    tb_logger=tensorboard_logger,\n",
    "    save_on_val=True,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f9b77c8ad0ae9b77",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Загрузим и протестируем обученную модель"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4d313998c7d92fd8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = UNet(in_channels=3, out_channels=1)\n",
    "model = load_checkpoint(\n",
    "    model=model, load_path=pjoin(CHECKPOINTS_DIR, \"model_checkpoint_best.pt\")\n",
    ")\n",
    "model = model.to(DEVICE)\n",
    "model.eval()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "941ce5ddfc64a7af",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "sample_idx = 0\n",
    "image, target = test_dataset[sample_idx]\n",
    "thresold = 0.8\n",
    "\n",
    "preds = F.sigmoid(model(image.unsqueeze(0).to(DEVICE))).squeeze(0)\n",
    "binary_preds = (preds > thresold)\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(9, 18))\n",
    "ax[0].imshow(image.numpy().transpose(1, 2, 0).astype(np.uint8))\n",
    "ax[0].set_title(\"Original Image\") \n",
    "ax[1].imshow(target.numpy().transpose(1, 2, 0).astype(np.uint8))\n",
    "ax[1].set_title(\"Target Mask\")\n",
    "ax[2].imshow(binary_preds.cpu().numpy()[0])\n",
    "ax[2].set_title(\"Predicted Mask\");"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5d250dadc8b8ea6c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
